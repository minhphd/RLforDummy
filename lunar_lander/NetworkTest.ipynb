{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from DQN import DQLearning, Conv2D\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "mps_device = torch.device('mps')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.mps.manual_seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code for datasets (we always use train and validation/ test set)\n",
    "data_transforms = transforms.Compose([\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# get train dataset\n",
    "# train_dataset = datasets.ImageFolder(\n",
    "#     root=os.path.join(opt.path_to_data, \"train\"),\n",
    "#     transform=data_transforms)\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=data_transforms)\n",
    "\n",
    "train_data_loader = data.DataLoader(train_dataset, 64)\n",
    "\n",
    "\n",
    "# test_dataset = datasets.ImageFolder(\n",
    "#     root=os.path.join(opt.path_to_data, \"test\"),\n",
    "#     transform=data_transforms)\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True, transform=data_transforms)\n",
    "\n",
    "test_data_loader = data.DataLoader(test_dataset, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=10, bias=True) ReLU() Linear(in_features=10, out_features=10, bias=True) ReLU() Linear(in_features=10, out_features=10, bias=True) ReLU() Linear(in_features=10, out_features=10, bias=True) LogSoftmax(dim=1)\n",
      "DQLearning(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (7): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/tq71ykt979gb8q34_nsq3ff00000gn/T/ipykernel_3532/1362562051.py:5: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = DQLearning(inputs=784, classes=10, hidden_units=[10,10,10])\n",
    "# net = Conv2D()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "net.apply(init_weights)\n",
    "net.to(mps_device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.65, epoch: 0/100: 100%|██████████| 938/938 [00:08<00:00, 109.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7977 / 10000 with accuracy 79.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.67, epoch: 1/100: 100%|██████████| 938/938 [00:08<00:00, 108.46it/s]\n",
      "Compute efficiency: 0.61, epoch: 2/100: 100%|██████████| 938/938 [00:08<00:00, 110.12it/s]\n",
      "Compute efficiency: 0.61, epoch: 3/100: 100%|██████████| 938/938 [00:08<00:00, 108.13it/s]\n",
      "Compute efficiency: 0.64, epoch: 4/100: 100%|██████████| 938/938 [00:08<00:00, 106.51it/s]\n",
      "Compute efficiency: 0.58, epoch: 5/100: 100%|██████████| 938/938 [00:08<00:00, 110.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8493 / 10000 with accuracy 84.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.65, epoch: 6/100: 100%|██████████| 938/938 [00:08<00:00, 110.58it/s]\n",
      "Compute efficiency: 0.60, epoch: 7/100: 100%|██████████| 938/938 [00:08<00:00, 113.14it/s]\n",
      "Compute efficiency: 0.64, epoch: 8/100: 100%|██████████| 938/938 [00:08<00:00, 111.76it/s]\n",
      "Compute efficiency: 0.56, epoch: 9/100: 100%|██████████| 938/938 [00:08<00:00, 115.74it/s]\n",
      "Compute efficiency: 0.63, epoch: 10/100: 100%|██████████| 938/938 [00:08<00:00, 116.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8418 / 10000 with accuracy 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.64, epoch: 11/100: 100%|██████████| 938/938 [00:08<00:00, 114.81it/s]\n",
      "Compute efficiency: 0.62, epoch: 12/100: 100%|██████████| 938/938 [00:08<00:00, 115.49it/s]\n",
      "Compute efficiency: 0.60, epoch: 13/100: 100%|██████████| 938/938 [00:08<00:00, 116.14it/s]\n",
      "Compute efficiency: 0.60, epoch: 14/100: 100%|██████████| 938/938 [00:08<00:00, 116.21it/s]\n",
      "Compute efficiency: 0.62, epoch: 15/100: 100%|██████████| 938/938 [00:08<00:00, 116.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8378 / 10000 with accuracy 83.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.59, epoch: 16/100: 100%|██████████| 938/938 [00:08<00:00, 115.61it/s]\n",
      "Compute efficiency: 0.58, epoch: 17/100: 100%|██████████| 938/938 [00:08<00:00, 115.35it/s]\n",
      "Compute efficiency: 0.62, epoch: 18/100: 100%|██████████| 938/938 [00:08<00:00, 116.11it/s]\n",
      "Compute efficiency: 0.61, epoch: 19/100: 100%|██████████| 938/938 [00:08<00:00, 114.67it/s]\n",
      "Compute efficiency: 0.59, epoch: 20/100: 100%|██████████| 938/938 [00:08<00:00, 115.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8473 / 10000 with accuracy 84.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.63, epoch: 21/100: 100%|██████████| 938/938 [00:08<00:00, 113.04it/s]\n",
      "Compute efficiency: 0.66, epoch: 22/100: 100%|██████████| 938/938 [00:08<00:00, 109.38it/s]\n",
      "Compute efficiency: 0.91, epoch: 23/100: 100%|██████████| 938/938 [00:08<00:00, 104.57it/s]\n",
      "Compute efficiency: 0.59, epoch: 24/100: 100%|██████████| 938/938 [00:08<00:00, 108.08it/s]\n",
      "Compute efficiency: 0.68, epoch: 25/100: 100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8180 / 10000 with accuracy 81.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.64, epoch: 26/100: 100%|██████████| 938/938 [00:09<00:00, 96.90it/s] \n",
      "Compute efficiency: 0.61, epoch: 27/100: 100%|██████████| 938/938 [00:08<00:00, 111.54it/s]\n",
      "Compute efficiency: 0.62, epoch: 28/100: 100%|██████████| 938/938 [00:08<00:00, 113.14it/s]\n",
      "Compute efficiency: 0.60, epoch: 29/100: 100%|██████████| 938/938 [00:08<00:00, 114.58it/s]\n",
      "Compute efficiency: 0.59, epoch: 30/100: 100%|██████████| 938/938 [00:08<00:00, 114.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8457 / 10000 with accuracy 84.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.66, epoch: 31/100: 100%|██████████| 938/938 [00:08<00:00, 114.26it/s]\n",
      "Compute efficiency: 0.55, epoch: 32/100: 100%|██████████| 938/938 [00:08<00:00, 108.96it/s]\n",
      "Compute efficiency: 0.63, epoch: 33/100: 100%|██████████| 938/938 [00:08<00:00, 112.12it/s]\n",
      "Compute efficiency: 0.66, epoch: 34/100: 100%|██████████| 938/938 [00:08<00:00, 107.72it/s]\n",
      "Compute efficiency: 0.65, epoch: 35/100: 100%|██████████| 938/938 [00:08<00:00, 110.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8442 / 10000 with accuracy 84.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.65, epoch: 36/100: 100%|██████████| 938/938 [00:08<00:00, 111.04it/s]\n",
      "Compute efficiency: 0.67, epoch: 37/100: 100%|██████████| 938/938 [00:08<00:00, 110.56it/s]\n",
      "Compute efficiency: 0.63, epoch: 38/100: 100%|██████████| 938/938 [00:08<00:00, 112.23it/s]\n",
      "Compute efficiency: 0.53, epoch: 39/100:  49%|████▊     | 457/938 [00:04<00:04, 107.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 37\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# # compute computation time and *compute_efficiency*\u001b[39;00m\n\u001b[1;32m     40\u001b[0m process_time \u001b[38;5;241m=\u001b[39m start_time\u001b[38;5;241m-\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mprepare_time\n",
      "File \u001b[0;32m~/miniconda3/envs/lunar_lander_pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lunar_lander_pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/lunar_lander_pytorch/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/lunar_lander_pytorch/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lunar_lander_pytorch/lib/python3.10/site-packages/torch/optim/adam.py:384\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    381\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# now we start the main loop\n",
    "epochs = 100\n",
    "for epoch in range(0, epochs):\n",
    "\n",
    "    # set models to train mode\n",
    "    net.train()\n",
    "\n",
    "    # use prefetch_generator and tqdm for iterating through data\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    # for loop going through dataset\n",
    "    pbar = tqdm(enumerate(train_data_loader),\n",
    "                    total=len(train_data_loader))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    loss = 0\n",
    "    for batch_idx, (img, label) in pbar:\n",
    "        img, label = img.to(mps_device), label.to(mps_device)\n",
    "        \n",
    "        # data preparation\n",
    "        flatten_img = torch.flatten(img, 1, -1)\n",
    "        \n",
    "        \n",
    "        # # It's very good practice to keep track of preparation time and computation time using tqdm to find any issues in your dataloader\n",
    "        prepare_time = start_time-time.time()\n",
    "        \n",
    "        output = net(flatten_img)\n",
    "        loss = criterion(output, label)\n",
    "    \n",
    "        # # forward and backward pass\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # # compute computation time and *compute_efficiency*\n",
    "        process_time = start_time-time.time()-prepare_time\n",
    "        pbar.set_description(\"Compute efficiency: {:.2f}, epoch: {}/{}\".format(\n",
    "            process_time/(process_time+prepare_time), epoch, epochs))\n",
    "        start_time = time.time()\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "    \n",
    "    # # maybe do a test pass every x epochs\n",
    "    if epoch % 5 == 0:\n",
    "        # bring models to evaluation mode\n",
    "        net.eval()\n",
    "        # Iterate over the test data loader\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for i, (test_img, test_label) in enumerate(test_data_loader):\n",
    "            test_img, test_label = test_img.to(mps_device), test_label.to(mps_device)\n",
    "            output_test = net(torch.flatten(test_img, 1, -1))\n",
    "            # output_test = net(test_img)\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(output_test, 1)\n",
    "            # Update accuracy statistics\n",
    "            num_correct += (predictions == test_label).sum().item()\n",
    "            num_samples += test_label.size(0)\n",
    "\n",
    "        # Calculate and print accuracy\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100 if num_samples > 0 else 0.0\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {accuracy:.2f}%')\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunar_lander_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
